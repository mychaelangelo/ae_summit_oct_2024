### AI Technical Terms Appendix

*These terms were extracted from the event transcripts with an LLM. The descriptions were then generated with the help of Google's Gemini 1.5 Pro model.*

**Activation Matrices:** In a neural network, activation matrices store the intermediate outputs of each layer.  These outputs are then passed as inputs to the next layer, allowing the network to process information hierarchically.

**Adaptive Agents:**  A reinforcement learning approach where the agent learns a curriculum of increasingly difficult tasks, adapting its training based on its current performance.  This helps the agent learn more efficiently by focusing on tasks that are neither too easy nor too hard.

**AlphaFold:**  A deep learning system developed by DeepMind that predicts the 3D structure of proteins from their amino acid sequence. It achieved groundbreaking accuracy and has revolutionized biological research.

**AlphaFold2:** The second version of AlphaFold, which significantly improved upon the original and became the state-of-the-art in protein structure prediction.

**Autoregression:** A type of machine learning model that predicts future values in a sequence based on past values.  Examples include predicting the next word in a sentence or the next frame in a video.

**Batch Reinforcement Learning:** A type of reinforcement learning where the agent learns from a fixed dataset of experiences, rather than interacting directly with an environment.  This is useful when real-world interaction is expensive or time-consuming.

**Bayesian Brain Hypothesis:**  A theory that suggests the brain works like a Bayesian inference engine, constantly updating its beliefs about the world based on sensory input and prior knowledge.

**Bayesian Model Selection:**  A method for choosing the best model among multiple candidates based on how well each model explains the observed data, taking into account model complexity.

**Bayesian Surprise:**  A measure of how much a new observation changes our beliefs about the world.  It quantifies the information gain from an observation.

**Behavioral Cloning:**  A type of imitation learning where an agent learns to mimic the behavior of an expert by observing their actions.

**Chain of Thought Prompting:** A prompting technique for large language models where the model is encouraged to generate intermediate reasoning steps before providing a final answer.  This can improve the model's performance on complex reasoning tasks.

**Classical Computing:** The traditional approach to computing where programs are explicitly designed to perform specific tasks. This contrasts with machine learning, where programs learn from data.

**Context Window:** In large language models, the context window refers to the amount of text the model can consider when generating a response. Larger context windows allow the model to access more information and potentially generate more coherent and relevant responses.

**Control System:** A system that manages, commands, directs, or regulates the behavior of other devices or systems.  These are often used in robotics, industrial automation, and other fields where precise control is necessary.

**Data Centric Machine Learning:** A paradigm shift in machine learning that emphasizes the importance of high-quality data for training models. It focuses on improving data quality, rather than just increasing data quantity or model complexity.

**Data Efficiency:**  The ability of a machine learning model to achieve good performance with a limited amount of training data.  This is crucial in applications where data is scarce or expensive to collect.

**Deep Generative Model:** A type of generative model that uses deep neural networks to learn complex data distributions.  These models can generate realistic samples of data, such as images, text, or audio.

**Deep Reinforcement Learning:**  A type of reinforcement learning that uses deep neural networks to approximate value functions or policies.

**Density Dynamics:**  The study of how probability distributions change over time.  This is important in understanding the behavior of dynamical systems, including physical, biological, and social systems.

**Diffusion Models:** A class of generative models that learn to generate data by reversing a diffusion process. They are known for producing high-quality images and videos.

**Divergent Thinking:**  A thought process or method used to generate creative ideas by exploring many possible solutions.

**Domain Adaptation:** A machine learning technique that adapts a model trained on one domain (e.g., music preferences) to perform well on a related but different domain (e.g., podcast preferences).

**Dreaming (in AI):**  In the context of world models, dreaming refers to the process where the model generates hypothetical sequences of events without any external input.

**Edge AI:**  Running AI algorithms on devices at the edge of the network, such as smartphones, sensors, or embedded systems.  This allows for faster processing, reduced latency, and improved privacy.

**Elbow (in Machine Learning):**  Short for "evidence lower bound," a term used in variational inference to describe a lower bound on the model evidence.

**Embodied AI:** Artificial intelligence that interacts with the physical world through a body, such as a robot.  This allows the AI to learn from direct experience and adapt to changing environments.

**Emerging AI:**  A level of artificial intelligence that is beginning to demonstrate capabilities comparable to humans in specific tasks.

**Entropy:**  A measure of disorder or randomness in a system. In information theory, it quantifies the uncertainty associated with a random variable.

**Epsilon Greedy:**  An exploration strategy in reinforcement learning where the agent chooses a random action with a small probability (epsilon) and otherwise chooses the action that it believes is best.

**Expected Free Energy:**  A quantity used in active inference to guide an agent's actions.  It combines the agent's beliefs about the world with its preferences and encourages exploration.

**Expected Information Gain:**  The amount of information an agent expects to gain by taking a particular action.  This is often used to guide exploration in reinforcement learning and active inference.

**Expected Utility Theory:** A theory in economics that describes how people make decisions under uncertainty by maximizing their expected utility.

**Extrinsic Value:**  Value derived from external rewards or outcomes.

**Federated Learning:** A machine learning technique where multiple devices collaboratively train a shared model without exchanging their local data. This is particularly useful for preserving privacy in applications like healthcare.

**Fitted Q Iteration:**  A batch reinforcement learning algorithm that iteratively improves a Q-function by fitting a model to the data.

**Fokker-Planck Equation:** A partial differential equation that describes the time evolution of the probability density function of a stochastic process.

**Foundation Model:**  A large machine learning model trained on a massive dataset, often using self-supervised learning. These models can be adapted to a wide range of downstream tasks.

**Free Energy Principle:**  A theory that suggests biological systems maintain their organization by minimizing free energy, a measure of surprise or uncertainty.

**Full Dreaming:** In the context of world models, full dreaming refers to the process where the model generates both actions and visuals, creating hypothetical gameplay sequences.

**Generative AI:**  A type of artificial intelligence that can create new content, such as text, images, audio, and code.

**Generative Interactive Environment:**  A simulated environment that is generated by an AI model and can be interacted with by both humans and AI agents.

**Genie:** A type of world model that learns an action-controllable environment from videos without requiring actions during training.

**Gradient Descent:** A method for training AI models by gradually adjusting parameters to reduce errors. In each step, it calculates the slope (or gradient) of the error and shifts the parameters a little in the opposite direction.

**Graph Neural Network (GNN):** A type of neural network designed to operate on graph-structured data.  GNNs can learn representations of nodes and edges in a graph, capturing relationships and dependencies between them.

**Helmholtz Decomposition:**  A mathematical theorem that states any vector field can be decomposed into the sum of a gradient field and a curl-free field.

**Heuristic Reasoning:**  A type of reasoning that relies on mental shortcuts or rules of thumb to make quick decisions, often without considering all available information.

**Hybrid Data:**  A combination of real-world data and synthetic data used for training machine learning models.

**In Context Learning:**  The ability of a large language model to learn to perform a task by being provided with a few examples within the context window, without any explicit training.

**Inductive Bias:**  The set of assumptions a machine learning model makes about the data.  This bias influences how the model learns and generalizes to new data.

**Infomax Principle:**  A principle that suggests biological systems maximize the amount of information they extract from their environment.

**Instruction Tuning:**  Fine-tuning a large language model on a dataset of instructions and corresponding outputs, allowing the model to follow instructions and perform a wider range of tasks.

**Iterative Practice:**  The process of repeatedly refining and improving a skill or design through iteration.

**Kalman Filter:**  An algorithm that estimates the state of a dynamical system from noisy measurements.

**KL Control:**  A control method that minimizes the Kullback-Leibler (KL) divergence between the desired distribution of states and the actual distribution of states.

**Knowledge Distillation:**  A technique where a smaller "student" model is trained to mimic the behavior of a larger "teacher" model.

**Langevin Equation:** A stochastic differential equation that describes the time evolution of a system subject to random forces.

**Large Language Model (LLM):**  A type of AI model trained on a massive text dataset that can generate human-like text, translate languages, write different kinds of creative content, and answer your questions in an informative way.

**Latent States:**  Hidden or unobserved variables in a model.

**Learnability Criterion:**  A data selection method that prioritizes data points that are expected to improve the model's performance the most.

**Linguistic Inquiry and Word Count (LIWC):** A text analysis tool that uses a dictionary to categorize words into psychological and linguistic categories.

**Log Marginal Likelihood:**  The logarithm of the probability of observing the data given a model.

**Lorawan:**  A low-power, wide-area network (LPWAN) technology designed for connecting battery-operated devices to the internet over long distances.

**Machine Learning (ML):**  A type of artificial intelligence that allows computers to learn from data without being explicitly programmed.

**Markov Blanket:**  A set of variables in a Bayesian network that separates a target variable from the rest of the network.

**Master Equation:** A differential equation that describes the time evolution of the probability distribution of a system.

**Matmuls:**  Short for "matrix multiplications," a fundamental operation in linear algebra and deep learning.

**Metacognition:**  "Thinking about thinking," or the ability to reflect on one's own cognitive processes.

**Meta Learning:**  "Learning to learn," or the process of learning how to learn new tasks more efficiently.

**Microcontroller:**  A small computer on a single integrated circuit containing a processor core, memory, and programmable input/output peripherals.

**Minimum Redundancy:**  A principle that suggests efficient representations of data should minimize redundancy.

**Model Evidence:**  The probability of observing the data given a model.

**Multi Agent Learning:**  A subfield of machine learning where multiple agents interact and learn to achieve individual or collective goals.

**Multimodal:**  Involving multiple modalities, such as text, images, audio, or sensor data.

**Neural Architecture Search:**  Automating the design of neural networks using algorithms.

**Neural Fitted Q Algorithms:**  A class of batch reinforcement learning algorithms that use neural networks to approximate Q-functions.

**Neurosimulator:**  A computer program that simulates the behavior of a neural system.

**Novelty (in AI):**  The generation of artifacts or behaviors that are new and unexpected to an observer.

**Open Endedness (in AI):**  The ability of an AI system to generate endlessly novel and learnable artifacts or behaviors.

**Optimal Control Theory:**  A mathematical framework for designing control systems that optimize a given objective function.

**Paired:**  A method for regret-based unsupervised environment design in reinforcement learning.

**Persistency (in AI):**  The ability of a model to persist user modifications to the input, such as adding new elements to a scene.

**Pig Breeder:**  An experiment that demonstrates the power of open-ended evolution by allowing users to selectively breed images.

**Plan and Solve Prompting:**  A prompting technique for large language models where the model is first asked to plan a solution and then execute the plan.

**Predictive Coding:**  A theory of brain function that suggests the brain constantly generates predictions about sensory input and updates its beliefs based on prediction errors.

**Prior Domain Knowledge:**  Knowledge about a specific domain that is incorporated into a machine learning model before training.

**Probabilistic Programming:**  A programming paradigm that combines probability theory and programming to represent and reason about uncertainty.

**Prompt Engineering:**  The process of designing effective prompts for large language models to elicit desired responses.

**Prompt Reader:**  A self-referential self-improvement system that evolves prompts for large language models.

**Pruning (in Machine Learning):**  Removing unnecessary connections or neurons from a neural network to reduce its size and improve efficiency.

**Q-Function:**  In reinforcement learning, a function that estimates the expected future reward for taking a given action in a given state.

**Quantization (in Machine Learning):**  Reducing the number of bits used to represent numbers in a model, making the model smaller and faster.

**Rainbow Teaming:**  A method for jailbreaking large language models by evolving adversarial prompts.

**Reinforcement Learning (RL):**  A type of machine learning where an agent learns to interact with an environment by receiving rewards or punishments for its actions.

**Reinforcement Learning from Human Feedback (RLHF):**  A technique for training reinforcement learning agents using feedback from humans.

**Rescorla-Wagner Model:** A model of classical conditioning that describes how associations between stimuli and responses are learned.

**Risk Sensitive Control:**  A control method that takes into account the risk associated with different actions.

**SAC (Soft Actor-Critic):**  A deep reinforcement learning algorithm that learns a stochastic policy.

**Scheduled Auxiliary Control:**  A reinforcement learning method that uses auxiliary rewards to encourage exploration and learn complex tasks by sequencing simpler tasks.

**Self Information:**  A measure of the information content of an event.

**Self Learning:**  Learning from one's own experiences without explicit instruction.

**Self Organization:**  The process by which a system spontaneously organizes itself into a more complex or ordered state.

**Self-Referential Self-Improvement:**  The ability of an AI system to improve its own performance by modifying its own code or parameters.

**Self-Supervised Learning:**  A type of machine learning where the model learns from the data itself, without explicit labels.

**Sense Making:**  The process of creating meaning from sensory input.

**Sensor Fusion:**  Combining data from multiple sensors to improve the accuracy and reliability of perception.

**SIM to Real Transfer:**  Transferring a model trained in simulation to the real world.

**Sora:** A video generation model developed by OpenAI that can create realistic and creative videos from text prompts.

**Sparse Variational Gaussian Processes:**  A method for approximating Gaussian processes using a sparse set of inducing points.

**Superhuman AI:**  A level of artificial intelligence that surpasses human capabilities in specific tasks.

**Supervised Learning:**  A type of machine learning where the model is trained on a labeled dataset of inputs and outputs.

**Synthetic Data:**  Data that is generated artificially, rather than collected from the real world.

**System 1 Thinking:**  Fast, intuitive, and automatic thinking.

**System 2 Thinking:**  Slow, deliberative, and analytical thinking.

**Tabular Q-Learning:**  A type of Q-learning that uses a table to store Q-values.

**Test Time:**  The amount of time a model is given to generate a response.

**Theory of Mind:**  The ability to understand and attribute mental states, such as beliefs, desires, and intentions, to oneself and others.

**TinyML:**  A field of machine learning that focuses on running AI algorithms on resource-constrained devices, such as microcontrollers.

**Transformer:**  A type of neural network architecture that uses attention mechanisms to process sequential data, such as text.

**Two Tower Model:**  A recommender system architecture that uses separate embeddings for users and items.

**Unconscious Inference:**  The idea that perception is an active process of inference, where the brain unconsciously infers the causes of sensory input.

**Unsupervised Learning:**  A type of machine learning where the model is trained on unlabeled data.

**Value Function:**  In reinforcement learning, a function that estimates the long-term value of being in a given state.

**Variational Autoencoder (VAE):**  A type of generative model that learns a latent representation of data.

**Variational Free Energy:**  A quantity used in variational inference to approximate the log marginal likelihood.

**Voyager:** An AI agent developed by Nvidia that demonstrates open-ended learning in Minecraft.

**WAM (World in Human Action Model):** A generative AI model trained on human gameplay data that can simulate game environments and generate gameplay sequences.

**Wasserstein Distance:**  A metric that measures the distance between two probability distributions.

**Weight Matrices:**  Matrices that store the weights or parameters of a neural network.

**World Model:**  A model that learns to simulate the dynamics of an environment.

**Zero-Shot Learning:**  The ability of a model to perform a task it has never seen before.
