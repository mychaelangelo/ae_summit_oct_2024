### Open-Endedness and General Intelligence

**Dr Katja Hofmann (Senior Principal Researcher at Microsoft)**

***

* **Katja Hofmann shared a novel approach to game simulation using neural networks that learn directly from human gameplay.** Her team trained a model on 8.6 years of continuous gameplay data. They processed 1.6 billion images and controller actions to create a complete game simulator without using the original game engine.

* **Hofmann is focused on empowering game creators rather than just training AI agents.** Her team studied game developers from AAA and indie studios to understand how generative AI could enhance creative workflows. Their research revealed two critical needs:
  - Support for iterative practice (building upon previous work)
  - Support for divergent thinking (exploring multiple creative possibilities)

* **The team identified three essential capabilities for effective creative AI tools:**
  - Consistency: Maintaining accurate 3D geometry, physics, and game mechanics
  - Diversity: Generating the full range of possible gameplay scenarios
  - Persistency: Preserving user modifications and allowing creative intervention

* **Their World and Human Action Model (WAM) showed clear learning progression over time.** The model mastered game mechanics in stages:
  - After one day: It grasped basic 3D geometry but struggled with long-term consistency
  - After one week: It handled improved physics including gravity but missed special mechanics
  - After one month: It mastered complex features like character flying abilities
  - Quantitative evaluation showed improved FVD scores—a measure of video quality—approaching real gameplay levels

* **The model achieved strong “persistency” capabilities.** Users could modify game scenes by adding power cells or characters. The model maintained these changes while creating appropriate interactions:
  - Single-frame modifications preserved 14% of power-ups and 55% of players
  - Five-frame sequences improved preservation to over 80% for power-ups and 90% for players

* **The research revealed key insights about scaling laws in game simulation.** World modeling aspects improved more naturally with increased data than behavioral learning. Both aspects improved with larger models. Their 900 million parameter model showed that careful architecture choices could enhance imitation learning.

* **The team compared autoregressive and diffusion models.** Diffusion models—AI systems that learn by gradually removing and adding noise to data—excel at creating high-resolution images. However, they currently struggle with maintaining consistent gameplay over time. Their research at NeurIPS showed promising improvements in diffusion models' consistency, beating previous records on Atari games.

* **Hofmann highlighted key challenges and opportunities ahead:**
  - Understanding trade-offs between different model architectures
  - Developing efficient planning capabilities in world models
  - Expanding systems to work across multiple games
  - Creating AI tools that enhance rather than replace human creativity
  - Building systems that support genuine human-AI collaboration in game development