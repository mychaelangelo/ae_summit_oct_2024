### Sociotechnical Limitations of LLMs

**Professor Maria Liakata (Professor of NLP at Queen Mary University of London)**

***

* **This presentation discussed some of the critical weaknesses of Large Language Models (LLMs) in sensitive fields like healthcare and law.** While LLMs excel at creative content, translation, and question-answering, they face serious limitations in high-stakes domains. These include:
  - Biases that can discriminate against certain groups
  - Privacy vulnerabilities that might expose sensitive data
  - Poor reasoning in complex scenarios
  - AI Decisions that lack clear explanations
  - Limited awareness of context and situation

* **Liakata has assembled a diverse team to create robust tests for evaluating LLM limitations.** The team combines experts in natural language processing, computer vision, cancer research, mental health, law, and ethics/social computing. This group:
  - Works with real users to define acceptable AI performance
  - Designs domain-specific tests
  - Creates practical success metrics
  - Tests how models handle sensitive data

* **The research targets three critical scenarios where LLM limitations could seriously impact outcomes:**
  - Medical diagnostics that combine images with patient histories and track changes over time
  - Mental health support, where privacy and fairness are vital, including therapy session summarization and self-management dialogue systems
  - Legal assistance, focusing on court case summarization and legal advice dialogue systems

* **For synthetic data evaluation, Liakata touched on a new method to review AI-generated text while protecting privacy.** This approach is detailed in an [upcoming paper](https://direct.mit.edu/coli/article/doi/10.1162/coli_a_00540/124625/Evaluating-Synthetic-Data-Generation-from-User) and examines three key aspects:
  - Meaning preservation: Keeping core messages accurate e.g. maintaining diagnosis details
  - Style preservation: Maintaining authentic voice, such as speech patterns
  - Divergence: Creating sufficient difference from source text to protect privacy

* **Liakata's team has developed new techniques to help AI understand time and sequence.** They use specialized methods (including “temporal rotational embeddings”) that help AI track how events relate to each other over time. Their work focuses on helping AI systems:
  - Track meaningful changes in people's health and behavior over time
  - Understand how mental health conditions develop and change
  - Monitor long-term patterns in medical and legal cases
  - Detect significant shifts in opinions and behavior

* **Liakata's work points to several key areas for future AI development.** The team is exploring:
  - Combining image analysis with patient data for cancer research
  - Making AI decisions more transparent
  - Creating personalized systems
  - Developing better tests with stakeholder input
  - Improving AI's understanding of time-based information
