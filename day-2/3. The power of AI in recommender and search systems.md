### The Power of AI in Recommender and Search Systems

**Dr Mounia Lalmas (Senior Director of Research at Spotify)**

***

* **Dr. Mounia Lalmas showcased how Spotify's massive scale drives their AI strategy.** As Senior Director of Research, she revealed that their systems serve over 600 million active users across music, podcasts, and audiobooks. The platform connects listeners' needs with creators' content through personalized recommendations on home screens, search results, and during listening sessions.

* **Spotify builds its recommendation foundation using user-created playlists as training data.** The team created a massive embedding space—similar to how Word2Vec translates words into numbers—from 4 billion playlists. In this space, tracks are like words and playlists are like sentences. This allows Spotify to represent tracks, users, artists, and genres mathematically, making sophisticated recommendations possible through similarity calculations.

* **Spotify personalizes content through a three-layer architecture.** The system works through:
  - Candidate generation (narrowing down millions of options to relevant choices)
  - Relevance ranking (organizing content meaningfully)
  - Business logic (adding non-algorithmic factors like new feature promotion)

* **When Spotify launched podcasts in 2019, they faced a classic challenge: how to recommend new content types without any listening data, aka the "cold-start problem."** The team developed a creative solution: they applied deep learning to what they knew about people's music preferences—from favorite genres to top artists—to predict what podcasts they might enjoy. This deep learning approach led to:
  - 15% increase in podcast streams
  - Successful connections like matching Spanish music fans to Spanish-language podcasts
  - A system that continues to power podcast recommendations today

* **For audiobook recommendations, Spotify evolved to using graph neural networks and large language models.** The 2023 approach combines:
  - Co-listening patterns between podcasts and audiobooks
  - Content understanding through LLM embeddings of titles and descriptions
  - A two-tower model architecture for scalability across their massive user base

* **Dr. Lalmas also demonstrated how they're using generative AI to improve content discovery through synthetic query generation.** Her team developed a system that learns from successful query-result pairs to generate additional queries that might help users discover content. This is particularly valuable for audiobooks, where titles might not fully reflect the content. The approach uses weak labeling (automatically generating training data by inferring patterns, such as identifying search intent based on how closely clicked results match the original query) to distinguish between narrow and broad search intents.

* **Dr. Lalmas outlined two key directions for the future of AI at Spotify:**
  - Build general representations across verticals (music, podcasts, audiobooks) through multimodality (In other words, rather than maintaining separate AI systems for music, podcasts, and audiobooks, Spotify aims to create unified AI models that can understand all forms of audio content simultaneously — similar to how humans can naturally process both music and spoken word)
  - Develop LLM-powered agents that can handle different user needs, from finding specific podcast episodes to suggesting mood-based music
